"""æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨

Phase 4: ç›‘æ§ä¸ä¼˜åŒ–
- æ”¶é›†æŸ¥è¯¢æ€§èƒ½æ•°æ®
- è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡ï¼ˆå¹³å‡å€¼ã€P50ã€P90ã€P99ï¼‰
- åªä¿ç•™æœ€è¿‘100æ¬¡è®°å½•ï¼Œé¿å…å†…å­˜æ³„æ¼
- é¢„ç•™æ‰©å±•æ¥å£ï¼ˆPrometheusã€CloudWatchï¼‰

P1-1 ä¿®å¤: å¹¶å‘å®‰å…¨
- æ·»åŠ  threading.Lock ä¿æŠ¤å…±äº«æ•°æ®
- ç¡®ä¿å¤šçº¿ç¨‹ç¯å¢ƒä¸‹æ•°æ®ä¸€è‡´æ€§
"""

import threading
from collections import defaultdict
from datetime import datetime, timezone

import logging

logger = logging.getLogger(__name__)


def _utc_now() -> datetime:
    """è¿”å›å½“å‰ UTC æ—¶é—´"""
    return datetime.now(timezone.utc)



class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨

    åŠŸèƒ½ï¼š
    1. è®°å½•æŸ¥è¯¢æ—¶é—´
    2. è®°å½• MCP åŠ è½½æ—¶é—´
    3. è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    4. æŒ‰è´¦å·éš”ç¦»ç»Ÿè®¡

    P1-1 ä¿®å¤ï¼šçº¿ç¨‹å®‰å…¨
    - ä½¿ç”¨ threading.Lock ä¿æŠ¤æ‰€æœ‰å…±äº«æ•°æ®æ“ä½œ
    - é˜²æ­¢å¹¶å‘è®¿é—®å¯¼è‡´çš„æ•°æ®ç«äº‰

    P1-2 ä¿®å¤ï¼šå†…å­˜æ³„æ¼é˜²æŠ¤
    - é™åˆ¶æœ€å¤§è´¦å·æ•°é‡ï¼ˆMAX_ACCOUNTS = 50ï¼‰
    - ä½¿ç”¨ LRU ç­–ç•¥æ¸…ç†æœ€æ—§è´¦å·
    - é˜²æ­¢å¤šç§Ÿæˆ·åœºæ™¯ä¸‹å†…å­˜æ— é™å¢é•¿
    """

    # P1-2: èµ„æºé™åˆ¶é…ç½®
    MAX_ACCOUNTS = 50  # æœ€å¤§è´¦å·æ•°é‡
    MAX_RECORDS_PER_ACCOUNT = 100  # æ¯ä¸ªè´¦å·æœ€å¤šä¿ç•™çš„è®°å½•æ•°

    def __init__(self):
        """åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨"""
        # æŸ¥è¯¢æ—¶é—´è®°å½•ï¼šaccount_id -> [duration1, duration2, ...]
        self.query_times: dict[str, list[float]] = defaultdict(list)

        # MCP åŠ è½½æ—¶é—´è®°å½•ï¼šaccount_id -> {server_type: [duration1, duration2, ...]}
        self.mcp_load_times: dict[str, dict[str, list[float]]] = defaultdict(
            lambda: defaultdict(list)
        )

        # P1-2: è´¦å·è®¿é—®æ—¶é—´è®°å½•ï¼ˆç”¨äº LRU æ¸…ç†ï¼‰
        self._account_access_time: dict[str, datetime] = {}

        # è®°å½•å¼€å§‹æ—¶é—´
        self.start_time = _utc_now()

        # P1-1: æ·»åŠ çº¿ç¨‹é”ä¿æŠ¤å¹¶å‘è®¿é—®
        self._lock = threading.Lock()

        # P2-2: æ±‡æ€»æ—¥å¿—è®¡æ•°å™¨
        self._query_count_since_last_summary = 0
        self._summary_interval = 10  # æ¯ 10 æ¬¡æŸ¥è¯¢è¾“å‡ºä¸€æ¬¡æ±‡æ€»

        logger.info("âœ… Phase 4: æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨å·²åˆå§‹åŒ–ï¼ˆçº¿ç¨‹å®‰å…¨ + å†…å­˜ä¿æŠ¤ï¼‰")

    def record_query_time(self, account_id: str, duration: float):
        """è®°å½•æŸ¥è¯¢æ—¶é—´ï¼ˆçº¿ç¨‹å®‰å…¨ + å†…å­˜ä¿æŠ¤ï¼‰

        Args:
            account_id: è´¦å·ID
            duration: æŸ¥è¯¢è€—æ—¶ï¼ˆç§’ï¼‰
        """
        try:
            # P1-1: ä½¿ç”¨é”ä¿æŠ¤å…±äº«æ•°æ®
            with self._lock:
                # P1-2: æ£€æŸ¥è´¦å·æ•°é‡é™åˆ¶
                if account_id not in self.query_times:
                    if len(self.query_times) >= self.MAX_ACCOUNTS:
                        self._cleanup_oldest_account()

                self.query_times[account_id].append(duration)

                # åªä¿ç•™æœ€è¿‘100æ¬¡è®°å½•ï¼Œé¿å…å†…å­˜æ³„æ¼
                if len(self.query_times[account_id]) > self.MAX_RECORDS_PER_ACCOUNT:
                    self.query_times[account_id] = self.query_times[account_id][
                        -self.MAX_RECORDS_PER_ACCOUNT :
                    ]

                # P1-2: æ›´æ–°è®¿é—®æ—¶é—´ï¼ˆLRUï¼‰
                self._account_access_time[account_id] = _utc_now()

                query_count = len(self.query_times[account_id])

                # P2-2: å¢åŠ æ±‡æ€»è®¡æ•°å™¨
                self._query_count_since_last_summary += 1

            # P2-2: æ—¥å¿—çº§åˆ«ä» info æ”¹ä¸º debugï¼ˆå‡å°‘æ—¥å¿—é‡ï¼‰
            logger.debug(
                f"ğŸ“Š æŸ¥è¯¢æ€§èƒ½ - è´¦å·: {account_id}, è€—æ—¶: {duration:.2f}ç§’, æ€»æŸ¥è¯¢æ•°: {query_count}"
            )

            # P2-2: æ¯ N æ¬¡æŸ¥è¯¢è¾“å‡ºä¸€æ¬¡æ±‡æ€»ï¼ˆå‡å°‘æ—¥å¿—é‡ 90%ï¼‰
            if self._query_count_since_last_summary >= self._summary_interval:
                self._output_summary_log()
                with self._lock:
                    self._query_count_since_last_summary = 0

        except Exception as e:
            # æŒ‡æ ‡æ”¶é›†å¤±è´¥ä¸å½±å“ä¸šåŠ¡
            logger.warning(": %s", e)

    def record_mcp_load_time(self, account_id: str, server_type: str, duration: float):
        """è®°å½• MCP å®¢æˆ·ç«¯åŠ è½½æ—¶é—´ï¼ˆçº¿ç¨‹å®‰å…¨ + å†…å­˜ä¿æŠ¤ï¼‰

        Args:
            account_id: è´¦å·ID
            server_type: MCP æœåŠ¡å™¨ç±»å‹
            duration: åŠ è½½è€—æ—¶ï¼ˆç§’ï¼‰
        """
        try:
            # P1-1: ä½¿ç”¨é”ä¿æŠ¤å…±äº«æ•°æ®
            with self._lock:
                # P1-2: æ£€æŸ¥è´¦å·æ•°é‡é™åˆ¶
                if account_id not in self.mcp_load_times:
                    if len(self.mcp_load_times) >= self.MAX_ACCOUNTS:
                        self._cleanup_oldest_account()

                self.mcp_load_times[account_id][server_type].append(duration)

                # åªä¿ç•™æœ€è¿‘100æ¬¡è®°å½•
                if len(self.mcp_load_times[account_id][server_type]) > self.MAX_RECORDS_PER_ACCOUNT:
                    self.mcp_load_times[account_id][server_type] = self.mcp_load_times[account_id][
                        server_type
                    ][-self.MAX_RECORDS_PER_ACCOUNT :]

                # P1-2: æ›´æ–°è®¿é—®æ—¶é—´ï¼ˆLRUï¼‰
                self._account_access_time[account_id] = _utc_now()

            # è®°å½•åˆ°æ—¥å¿—ï¼ˆå·²ç»æ˜¯ debug çº§åˆ«ï¼‰
            logger.debug(
                f"ğŸ“Š MCPåŠ è½½ - è´¦å·: {account_id}, ç±»å‹: {server_type}, è€—æ—¶: {duration:.2f}ç§’"
            )

        except Exception as e:
            logger.warning("MCP: %s", e)

    def get_stats(self) -> dict:
        """è·å–æ•´ä½“ç»Ÿè®¡ä¿¡æ¯ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ï¼š
            - total_queries: æ€»æŸ¥è¯¢æ•°
            - total_accounts: è´¦å·æ•°
            - avg_time: å¹³å‡æŸ¥è¯¢æ—¶é—´
            - p50: 50åˆ†ä½æ•°
            - p90: 90åˆ†ä½æ•°
            - p99: 99åˆ†ä½æ•°
            - uptime_seconds: è¿è¡Œæ—¶é•¿
        """
        try:
            # P1-1: ä½¿ç”¨é”ä¿æŠ¤è¯»å–æ“ä½œ
            with self._lock:
                # æ”¶é›†æ‰€æœ‰æŸ¥è¯¢æ—¶é—´ï¼ˆåˆ›å»ºå‰¯æœ¬é¿å…é•¿æ—¶é—´æŒé”ï¼‰
                all_times = []
                for times in self.query_times.values():
                    all_times.extend(times)

                total_accounts = len(self.query_times)

            if not all_times:
                return {
                    "total_queries": 0,
                    "total_accounts": 0,
                    "uptime_seconds": (_utc_now() - self.start_time).total_seconds(),
                }

            # æ’åºç”¨äºè®¡ç®—ç™¾åˆ†ä½æ•°ï¼ˆåœ¨é”å¤–æ‰§è¡Œï¼Œé¿å…é˜»å¡ï¼‰
            all_times.sort()
            total = len(all_times)

            return {
                "total_queries": total,
                "total_accounts": total_accounts,
                "avg_time": sum(all_times) / total,
                "min_time": all_times[0],
                "max_time": all_times[-1],
                "p50": all_times[int(total * 0.50)],
                "p90": all_times[int(total * 0.90)],
                "p95": all_times[int(total * 0.95)],
                "p99": all_times[min(int(total * 0.99), total - 1)],
                "uptime_seconds": (_utc_now() - self.start_time).total_seconds(),
            }

        except Exception as e:
            logger.warning(": %s", e)
            return {"error": str(e)}

    def get_account_stats(self, account_id: str) -> dict:
        """è·å–æŒ‡å®šè´¦å·çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰

        Args:
            account_id: è´¦å·ID

        Returns:
            è´¦å·ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # P1-1: ä½¿ç”¨é”ä¿æŠ¤è¯»å–æ“ä½œ
            with self._lock:
                times = list(self.query_times.get(account_id, []))  # åˆ›å»ºå‰¯æœ¬

            if not times:
                return {"account_id": account_id, "total_queries": 0}

            times_sorted = sorted(times)
            total = len(times_sorted)

            return {
                "account_id": account_id,
                "total_queries": total,
                "avg_time": sum(times_sorted) / total,
                "min_time": times_sorted[0],
                "max_time": times_sorted[-1],
                "p50": times_sorted[int(total * 0.50)],
                "p90": times_sorted[int(total * 0.90)],
                "p99": times_sorted[min(int(total * 0.99), total - 1)],
            }

        except Exception as e:
            logger.warning(": %s", e)
            return {"error": str(e)}

    def get_mcp_stats(self) -> dict:
        """è·å– MCP åŠ è½½ç»Ÿè®¡ä¿¡æ¯ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰

        Returns:
            MCP åŠ è½½ç»Ÿè®¡
        """
        try:
            # P1-1: ä½¿ç”¨é”ä¿æŠ¤è¯»å–æ“ä½œ
            with self._lock:
                # åˆ›å»ºæ·±æ‹·è´é¿å…é•¿æ—¶é—´æŒé”
                mcp_load_times_copy = {}
                for account_id, server_times in self.mcp_load_times.items():
                    mcp_load_times_copy[account_id] = {}
                    for server_type, times in server_times.items():
                        mcp_load_times_copy[account_id][server_type] = list(times)

            stats = {}
            for account_id, server_times in mcp_load_times_copy.items():
                stats[account_id] = {}

                for server_type, times in server_times.items():
                    if times:
                        stats[account_id][server_type] = {
                            "count": len(times),
                            "avg_time": sum(times) / len(times),
                            "min_time": min(times),
                            "max_time": max(times),
                        }

            return stats

        except Exception as e:
            logger.warning("MCP: %s", e)
            return {"error": str(e)}

    def _output_summary_log(self):
        """è¾“å‡ºç®€çŸ­çš„æ±‡æ€»æ—¥å¿—ï¼ˆP2-2: æ¯ N æ¬¡æŸ¥è¯¢è°ƒç”¨ä¸€æ¬¡ï¼‰

        ç”¨äºå‡å°‘æ—¥å¿—é‡ï¼ŒåŒæ—¶ä¿æŒå¯è§‚æµ‹æ€§
        """
        try:
            stats = self.get_stats()

            if stats.get("total_queries", 0) == 0:
                return

            # ç®€çŸ­çš„æ±‡æ€»æ—¥å¿—ï¼ˆå•è¡Œï¼‰
            logger.info(
                f"ğŸ“Š æŸ¥è¯¢æ±‡æ€» - "
                f"æ€»æ•°: {stats['total_queries']}, "
                f"è´¦å·: {stats['total_accounts']}, "
                f"å¹³å‡: {stats['avg_time']:.2f}s, "
                f"P90: {stats['p90']:.2f}s, "
                f"P99: {stats['p99']:.2f}s"
            )

        except Exception as e:
            logger.debug(": %s", e)

    def log_summary(self):
        """è¾“å‡ºè¯¦ç»†çš„ç»Ÿè®¡æ‘˜è¦åˆ°æ—¥å¿—

        ç”¨äºå®šæœŸè¾“å‡ºæ€§èƒ½æ‘˜è¦ï¼Œæ–¹ä¾¿æ—¥å¿—åˆ†æ
        """
        try:
            stats = self.get_stats()

            if stats.get("total_queries", 0) == 0:
                logger.info("ğŸ“Š æ€§èƒ½æ‘˜è¦ - æš‚æ— æŸ¥è¯¢æ•°æ®")
                return

            logger.info("=" * 60)
            logger.info("ğŸ“Š æ€§èƒ½ç»Ÿè®¡æ‘˜è¦")
            logger.info("=" * 60)
            logger.info(": %s", stats['total_queries'])
            logger.info(": %s", stats['total_accounts'])
            logger.info("è¿è¡Œæ—¶é•¿: {stats['uptime_seconds']:.0f}ç§’")
            logger.info("å¹³å‡æŸ¥è¯¢æ—¶é—´: {stats['avg_time']:.2f}ç§’")
            logger.info("æœ€å¿«æŸ¥è¯¢: {stats['min_time']:.2f}ç§’")
            logger.info("æœ€æ…¢æŸ¥è¯¢: {stats['max_time']:.2f}ç§’")
            logger.info("P50 (ä¸­ä½æ•°): {stats['p50']:.2f}ç§’")
            logger.info("P90: {stats['p90']:.2f}ç§’")
            logger.info("P95: {stats['p95']:.2f}ç§’")
            logger.info("P99: {stats['p99']:.2f}ç§’")
            logger.info("=" * 60)

            # æ€§èƒ½è¯„ä¼°
            p90 = stats["p90"]
            if p90 < 1.0:
                logger.info("âœ… æ€§èƒ½è¯„ä¼°: ä¼˜ç§€ (P90 < 1ç§’)")
            elif p90 < 2.0:
                logger.info("âœ… æ€§èƒ½è¯„ä¼°: è‰¯å¥½ (P90 < 2ç§’)")
            elif p90 < 3.0:
                logger.info("âš ï¸ æ€§èƒ½è¯„ä¼°: å¯æ¥å— (P90 < 3ç§’)")
            else:
                logger.info("âŒ æ€§èƒ½è¯„ä¼°: éœ€ä¼˜åŒ– (P90 >= 3ç§’)")

        except Exception as e:
            logger.warning(": %s", e)

    def _cleanup_oldest_account(self):
        """æ¸…ç†æœ€ä¹…æœªä½¿ç”¨çš„è´¦å·ï¼ˆLRUç­–ç•¥ï¼‰

        P1-2: é˜²æ­¢å†…å­˜æ³„æ¼
        - å½“è´¦å·æ•°é‡è¾¾åˆ°ä¸Šé™æ—¶è§¦å‘
        - æ¸…ç†æœ€ä¹…æœªè®¿é—®çš„è´¦å·æ•°æ®
        - é‡Šæ”¾å†…å­˜ç©ºé—´

        æ³¨æ„ï¼šæ­¤æ–¹æ³•å¿…é¡»åœ¨æŒæœ‰ self._lock çš„æƒ…å†µä¸‹è°ƒç”¨
        """
        if not self._account_access_time:
            logger.warning("âš ï¸ [Metrics] æ— å¯æ¸…ç†çš„è´¦å·")
            return

        # æ‰¾åˆ°æœ€æ—§çš„è´¦å·
        oldest_account = min(self._account_access_time.items(), key=lambda x: x[1])[0]

        # æ¸…ç†è´¦å·æ•°æ®
        if oldest_account in self.query_times:
            del self.query_times[oldest_account]
        if oldest_account in self.mcp_load_times:
            del self.mcp_load_times[oldest_account]
        if oldest_account in self._account_access_time:
            del self._account_access_time[oldest_account]

        logger.info("[Metrics] : %s (LRU)", oldest_account)


# å…¨å±€å•ä¾‹
_metrics: PerformanceMetrics = None


def get_metrics() -> PerformanceMetrics:
    """è·å–å…¨å±€æŒ‡æ ‡æ”¶é›†å™¨å•ä¾‹

    Returns:
        PerformanceMetrics å®ä¾‹
    """
    global _metrics
    if _metrics is None:
        _metrics = PerformanceMetrics()
    return _metrics
